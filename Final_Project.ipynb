{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMU Final Project\n",
    "\n",
    "### Jingchen Liang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "#import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent - Finding the Minimum (Unconstrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 1. x^2 + 4*x + 4__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2: Beale Function has minimum at (3, 0.5)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda x : x[0]**2 + 4*x[0] + 4\n",
    "beale = lambda x : (1.5-x[0]+x[0]*x[1])**2 + (2.25-x[0]+x[0]*(x[1]**2))**2 + (2.625-x[0]+x[0]*(x[1]**3))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the gradient\n",
    "def grad(fun, x, eps=1e-7):\n",
    "    dim = x.shape[0]\n",
    "    gradient = np.zeros(dim)\n",
    "    delta = np.eye(dim)\n",
    "    for i in range(dim):\n",
    "        gradient[i] = (fun(x+eps * delta[i]) - fun(x))/eps\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent algorithm\n",
    "def gradient_descent(fun,x0,epsilon,k,alpha):\n",
    "    x_n = x0\n",
    "    x_new = np.array([])\n",
    "    prediction = -10\n",
    "\n",
    "    while abs(fun(x_n) - prediction) > epsilon:\n",
    "        prediction = fun(x_n)\n",
    "        x_new = np.append(x_new, x_n)\n",
    "        x_n = x_n - alpha*grad(fun,x_n)\n",
    "        k = k+1\n",
    "    \n",
    "    return x_n, k, x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exmaple 1__ For the f1 function, we set the starting point is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  4.989250300013737e-05 at x =  [-1.99293654] in 7434 iterations\n",
      "Execution time: 0.15836501121520996 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([10])\n",
    "results = gradient_descent(f1,x0,1e-7,0,0.0005)\n",
    "\n",
    "print(\"Function Value: \", f1(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal point is near -2, and about 7400 iterations were performed in 1.4 seconds. If we define the learning rate alpha = 0.00005, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  0.0004998413896064591 at x =  [-1.97764287] in 62852 iterations\n",
      "Execution time: 1.7342917919158936 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([10])\n",
    "results = gradient_descent(f1,x0,1e-7,0,0.00005)\n",
    "\n",
    "print(\"Function Value: \", f1(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2__ For the beale function, we set the starting point is [4,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  0.00036792353469975976 at x =  [3.0492535  0.51203347] in 28252 iterations\n",
      "Execution time: 1.248945951461792 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([4,0])\n",
    "results = gradient_descent(beale,x0,1e-7,0,0.0005)\n",
    "\n",
    "print(\"Function Value: \", beale(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal point is near [3, 0.5], and about 28000 iterations were performed in 1.4 seconds. If we define the learning rate alpha = 0.00005, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  0.004971965227686887 at x =  [3.1956725  0.54491271] in 174899 iterations\n",
      "Execution time: 24.51436185836792 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([4,0])\n",
    "results = gradient_descent(beale,x0,1e-7,0,0.00005)\n",
    "\n",
    "print(\"Function Value: \", beale(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althoguh more iterations were performed, the accuracy is lower than the previous one. We need to add a backtracking line search to define alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Back_Armijo(fun,x):                 \n",
    "    alpha = 1                    \n",
    "    beta = 0.8\n",
    "    while fun(x - alpha*grad(fun,x)) >= (fun(x) - beta*alpha*(grad(fun,x).T@grad(fun,x))):\n",
    "        alpha *= beta\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new gradient descent algorithm\n",
    "def gradient_descent(fun,x0,epsilon):\n",
    "    x_n = x0\n",
    "    x_new = np.array([])\n",
    "    prediction = -10\n",
    "    k = 0\n",
    "\n",
    "    while abs(fun(x_n) - prediction) > epsilon:\n",
    "        prediction = fun(x_n)\n",
    "        x_new = np.append(x_new, x_n)\n",
    "        alpha = Back_Armijo(fun,x_n)\n",
    "        x_n = x_n - alpha*grad(fun,x_n)\n",
    "        k = k+1\n",
    "    \n",
    "    return x_n, k, x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  4.5759936032060675e-06 at x =  [3.00535374 0.50129886] in 219 iterations\n",
      "Execution time: 0.28815317153930664 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([4,0])\n",
    "results = gradient_descent(beale,x0,1e-7)\n",
    "\n",
    "print(\"Function Value: \", beale(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, less than 300 steps were performed, which is faster！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also redo f1, and only 27 steps are necessary to operate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  3.7265332597513634e-08 at x =  [-1.99980696] in 27 iterations\n",
      "Execution time: 0.011459827423095703 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x0 = np.array([10])\n",
    "results = gradient_descent(f1,x0,1e-7)\n",
    "\n",
    "print(\"Function Value: \", f1(results[0]), \"at x = \", results[0], \"in\", results[1], \"iterations\")\n",
    "\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 Direct solution - pseudo inverse\n",
    "\n",
    "Pseudo inverse of the features matrix x multiplied with y gives the solution to this mean squared minimization or regression problem directly. This can be expressed as :\n",
    "$$\n",
    "   Y= XA \n",
    "$$\n",
    "\n",
    "$$\n",
    "A = (X^T X)^{-1}X^T Y\n",
    "$$\n",
    "\n",
    "where $X$ is the features set with a column of 1's appended for the bias value computation \n",
    "\n",
    "We can compare the gradient descent parameter values with direct solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_inverse(x,y):\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 Direct solution - gradient descent\n",
    "\n",
    "We can also use similar gradient descent algorithm that we just created. Here, we neeed to input x, y, and we focus on finding the parameter θ values.\n",
    "\n",
    "$$\n",
    "y = θ^Tx + ε\n",
    "$$\n",
    "or in other words minimize the loss function\n",
    "$$\n",
    "H(θ) = \\frac{1}{2n}\\sum_{i=1}^n(θ^Tx_i - y_i)^2 \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function for the linear regression\n",
    "linear_cost = lambda x,y,theta : np.sum((x @ theta - y)**2)/ (2 * len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_grad(fun, x, y, theta, eps=1e-7):\n",
    "    dim = theta.shape[0]\n",
    "    gradient = np.zeros(dim)\n",
    "    delta = np.eye(dim)\n",
    "    for i in range(dim):\n",
    "        gradient[i] = (fun(x,y,(theta+eps*delta[i])) - fun(x, y, theta))/eps\n",
    "    return gradient\n",
    "\n",
    "# Another way to calculate the gradient is to take partial derivative of linear_cost. We use the similar process in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_Back_Armijo(fun,x, y, theta):                 \n",
    "    alpha = 1                    \n",
    "    beta = 0.8\n",
    "    while fun(x,y,theta - alpha*linear_grad(fun,x,y,theta)) >= (fun(x,y,theta) - beta*alpha*((linear_grad(fun,x,y,theta).T @ linear_grad(fun,x,y,theta)))):\n",
    "        alpha *= beta\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gradient_descent(fun,x,y,theta0,epsilon):\n",
    "    theta_n = theta0\n",
    "    theta_new = np.array([])\n",
    "    prediction = -10\n",
    "    k = 0\n",
    "\n",
    "    while abs(fun(x,y,theta_n) - prediction) > epsilon:\n",
    "        prediction = fun(x,y,theta_n)\n",
    "        theta_new = np.append(theta_new, theta_n)\n",
    "        alpha = linear_Back_Armijo(fun,x, y, theta_n)\n",
    "        theta_n = theta_n - alpha*linear_grad(fun,x,y,theta_n)\n",
    "        k = k+1\n",
    "    \n",
    "    return theta_n, k, theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1: How does the gradient descent accuracy compare with the standard method?__\n",
    "\n",
    "We will try 4 different functions to check our algorithm, and we comapre the parameter results with values from generalized_inverse function.\n",
    "\n",
    "Ex1: linear and univariate \n",
    "\n",
    "Ex2: linear and multivariate \n",
    "\n",
    "Ex3: nonlinear and univariate \n",
    "\n",
    "Ex4: nonlinear and multivariate \n",
    "\n",
    "For each example, we create the data (x and y values), we we estimate the theta values. In addition, we add a random noise from different PDFs.\n",
    "\n",
    "Each time we may have different $ x_i $ and $ y_i $. We may use np.random.seed() to make the results reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 1:__ Linear and univariate - simple linear regression\n",
    "\n",
    "$$\n",
    "y_i = θ_0x_0 + θ_1x_1 =  θ_0 + θ_1x_1 + UniformNoise \\;\\;\\;\\;\\;\\;  given \\;\\;\\ x_0 = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateData1(numObs, low, high, mean, sd, df):\n",
    "    \"\"\"\n",
    "    numObs: number of observations that we want to create\n",
    "    low, high: low and high boundaries of uniform distribution \n",
    "    mean, variance: mean and variance of the normal distribution \n",
    "    \"\"\"\n",
    "    x = np.zeros((numObs, 2))\n",
    "    y_uni = np.zeros(numObs)\n",
    "    y_nor = np.zeros(numObs)\n",
    "    y_t = np.zeros(numObs)\n",
    "    \n",
    "    for i in range(numObs):\n",
    "        x[i][0] = 1   # since x0 is 1 defined by hypothesis\n",
    "        x[i][1] = i\n",
    "        y_uni[i] = i + np.random.uniform(low, high)\n",
    "        y_nor[i] = i + np.random.normal(mean, sd)\n",
    "        y_t[i] = i + np.random.standard_t(df)\n",
    "    return x, y_uni, y_nor, y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates many y columns according to different PDFs. Here, we use uniform distribution noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(90)\n",
    "x1, y1_uni, y1_nor, y1_t = CreateData1(500,-30,30,0,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.97677002,  1.00298679])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can first see the generalized inverse solution\n",
    "generalized_inverse(x1, y1_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.9519177669585"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the min H(θ) for generalized inverse solution\n",
    "linear_cost(x1, y1_uni,generalized_inverse(x1, y1_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  135.96871480640007 , when θ =  [-1.61074562  1.00188825] in 52883 iterations\n",
      "Execution time: 489.30465388298035 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([3,3]) # starting point\n",
    "\n",
    "Ex1_results = linear_gradient_descent(linear_cost,x1,y1_uni,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x1,y1_uni,Ex1_results[0]), \", when θ = \", Ex1_results[0], \"in\", Ex1_results[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 490 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also plot the regression line\n",
    "reg_line = Ex1_results[0][0]*x1[:,0] + Ex1_results[0][1]*x1[:,1]\n",
    "plt.plot(x1[:,1],y1_uni,'o')\n",
    "plt.plot(reg_line, linewidth = 4, color = 'red')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2:__ Linear and multivariate\n",
    "\n",
    "We add a new varaible x2:\n",
    "\n",
    "$$\n",
    "y = θ_0x_0 + θ_1x_1 + θ_2x_2=  θ_0 + θ_1x_1 + θ_2x_2 + NormalNoise\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "def CreateData2(numObs, interval, low, high, mean, sd, df):\n",
    "    x = np.zeros((numObs, 3))\n",
    "    y_uni = np.zeros(numObs)\n",
    "    y_nor = np.zeros(numObs)\n",
    "    y_t = np.zeros(numObs)\n",
    "    \n",
    "    for i in range(numObs):\n",
    "        x[i][0] = 1   \n",
    "        x[i][1] = i\n",
    "        x[i][2] = np.random.choice(interval)        \n",
    "        y_uni[i] = i + np.random.choice(interval) + np.random.uniform(low, high)\n",
    "        y_nor[i] = i + np.random.choice(interval) + np.random.normal(mean,sd)\n",
    "        y_t[i] = i + np.random.choice(interval) + np.random.standard_t(df)\n",
    "    return x, y_uni, y_nor, y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use normal distribution noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(90)\n",
    "x2, y2_uni, y2_nor, y2_t = CreateData2(500,10,-30,30,0,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.47741651, 0.9938915 , 0.06160634])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x2, y2_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.668833753757426"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_cost(x2,y2_nor,generalized_inverse(x2, y2_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  50.69562572030049 , when θ =  [5.89294861 0.99503994 0.11256769] in 64747 iterations\n",
      "Execution time: 843.9593300819397 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([2,2,2]) # starting point\n",
    "\n",
    "Ex2_results = linear_gradient_descent(linear_cost,x2,y2_nor,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x2,y2_nor,Ex2_results[0]), \", when θ = \", Ex2_results[0], \"in\", Ex2_results[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 840 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 3:__ Nonlinear and univariate\n",
    "\n",
    "$$\n",
    "y = θ_0 + θ_1x_1 + θ_2x_1^2 + NormalNoise\n",
    "$$\n",
    "\n",
    "We still have one independent variable x1 here, but one is squared. However, this model is still linear in the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "def CreateData3(numObs, low, high, mean, sd, df):\n",
    "    x = np.zeros((numObs, 3))\n",
    "    y_uni = np.zeros(numObs)\n",
    "    y_nor = np.zeros(numObs)\n",
    "    y_t = np.zeros(numObs)\n",
    "    \n",
    "    for i in range(numObs):\n",
    "        x[i][0] = 1   \n",
    "        x[i][1] = i/40\n",
    "        x[i][2] = np.square(i/40)        \n",
    "        y_uni[i] = i/40 + np.square(i/40) + np.random.uniform(low, high)\n",
    "        y_nor[i] = i/40 + np.square(i/40) + np.random.normal(mean,sd)\n",
    "        y_t[i] = i/40 + np.square(i/40) + np.random.standard_t(df)\n",
    "    return x, y_uni, y_nor, y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use normal distribution noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(90)\n",
    "x3, y3_uni, y3_nor, y3_t = CreateData3(500,-30,30,0,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13369471, 0.7829617 , 1.01371879])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3, y3_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.29866641997017"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_cost(x3,y3_nor,generalized_inverse(x3, y3_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  56.30064819042357 , when θ =  [1.32152001 0.72085305 1.01792683] in 1602 iterations\n",
      "Execution time: 14.71224331855774 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([7,7,7])\n",
    "\n",
    "Ex3_results = linear_gradient_descent(linear_cost,x3,y3_nor,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x3,y3_nor,Ex3_results[0]), \", when θ = \", Ex3_results[0], \"in\", Ex3_results[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 15 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 4:__ Nonlinear and multivariate\n",
    "\n",
    "Two predictors x1 and x2, and we apply expoenntial function in x2\n",
    "\n",
    "$$\n",
    "y = θ_0x_0 + θ_1x_1 + θ_2x_2=  θ_0 + θ_1x_1 + θ_2exp(x2) + NormalNoise\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateData4(numObs, interval, low, high, mean, sd, df):\n",
    "    x = np.zeros((numObs, 3))\n",
    "    y_uni = np.zeros(numObs)\n",
    "    y_nor = np.zeros(numObs)\n",
    "    y_t = np.zeros(numObs)\n",
    "    \n",
    "    for i in range(numObs):\n",
    "        x[i][0] = 1   \n",
    "        x[i][1] = i\n",
    "        x[i][2] = np.exp(np.random.choice(interval))        \n",
    "        y_uni[i] = i + np.exp(np.random.choice(interval)) + np.random.uniform(low, high)\n",
    "        y_nor[i] = i + np.exp(np.random.choice(interval)) + np.random.normal(mean,sd)\n",
    "        y_t[i] = i + np.exp(np.random.choice(interval)) + np.random.standard_t(df)\n",
    "    return x, y_uni, y_nor, y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use normal distribution noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(90)\n",
    "x4, y4_uni, y4_nor, y4_t = CreateData4(500,5,-30,30,0,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.74141216,  0.99332467, -0.06167027])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x4, y4_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237.62770197185577"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_cost(x4,y4_nor,generalized_inverse(x4, y4_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  237.6467679081287 , when θ =  [19.31904309  0.99439465 -0.05787925] in 94547 iterations\n",
      "Execution time: 1704.5454320907593 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([5,5,5])\n",
    "\n",
    "Ex4_results = linear_gradient_descent(linear_cost,x4,y4_nor,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x4,y4_nor,Ex4_results[0]), \", when θ = \", Ex4_results[0], \"in\", Ex4_results[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 1704 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1 Conclusion:__\n",
    "\n",
    "From the above 4 example, no matter what the regression function that we defined, the optimal parameter theta values are all close to the values obtained from the generalized inverse method, implying that our algorithm is correct with  accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2 How linear regression accuracy is affected by the noise from different probability density functions?__\n",
    "\n",
    "For each above functions, for the random noise, we try different probability distribution functions, and compare the error norm $$ |y_{hat} - y_i| $$\n",
    "\n",
    "We mainly compare the uniform and normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frist, define the error norm function\n",
    "def norm_error(y_hat,y):\n",
    "    error = y_hat -y\n",
    "    return np.linalg.norm(error,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 1__\n",
    "\n",
    "Previously, we use the uniform noise. Here, we also calculate the normal noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Uniform distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.97677002,  1.00298679])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x1, y1_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.61074562,  1.00188825])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ex1_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_uniform = x1 @ Ex1_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the uniform distribution is :  7041.236071821755\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the uniform distribution is : \", norm_error(y_hat_uniform,y1_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Normal distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77857531, 0.99885259])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x1, y1_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  56.32803328965713 , when θ =  [1.14248649 0.99776039] in 38332 iterations\n",
      "Execution time: 327.86821579933167 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([3,3])\n",
    "Ex1_nor_result = linear_gradient_descent(linear_cost,x1,y1_nor,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x1,y1_nor,Ex1_nor_result[0]), \", when θ = \", Ex1_nor_result[0], \"in\", Ex1_nor_result[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14248649, 0.99776039])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ex1_nor_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_normal = x1 @ Ex1_nor_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the normal distribution is :  4317.430311353488\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the normal distribution is : \", norm_error(y_hat_normal,y1_nor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 2__\n",
    "\n",
    "Previously, we use the normal noise. Here, we also calculate the uniform noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Uniform distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.11085004,  0.99893174, -0.08308856])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x2, y2_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  139.9236415985326 , when θ =  [ 5.52660297  1.00007974 -0.03214646] in 62827 iterations\n",
      "Execution time: 802.836098909378 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([2,2,2])\n",
    "Ex2_uni_result = linear_gradient_descent(linear_cost,x2,y2_uni,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x2,y2_uni,Ex2_uni_result[0]), \", when θ = \", Ex2_uni_result[0], \"in\", Ex2_uni_result[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_uniform2 = x2 @ Ex2_uni_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the uniform distribution is :  7139.971524066167\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the uniform distribution is : \", norm_error(y_hat_uniform2,y2_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Normal distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.89294861, 0.99503994, 0.11256769])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ex2_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_normal2 = x2 @ Ex2_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the normal distribution is :  4039.8819787334332\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the normal distribution is : \", norm_error(y_hat_normal2,y2_nor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 3__\n",
    "Previously, we use the normal noise. Here, we also calculate the uniform noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Uniform distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.47882943,  1.36142807,  0.9806047 ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3, y3_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  135.928416523858 , when θ =  [-2.28969871  1.29888809  0.98484611] in 1916 iterations\n",
      "Execution time: 18.359938621520996 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([7,7,7])\n",
    "Ex3_uni_result = linear_gradient_descent(linear_cost,x3,y3_uni,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x3,y3_uni,Ex3_uni_result[0]), \", when θ = \", Ex3_uni_result[0], \"in\", Ex3_uni_result[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_uniform3 = x3 @ Ex3_uni_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the uniform distribution is :  7039.007888254393\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the uniform distribution is : \", norm_error(y_hat_uniform3,y3_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Normal distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13369471, 0.7829617 , 1.01371879])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3, y3_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.32152001, 0.72085305, 1.01792683])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ex3_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_normal3 = x3 @ Ex3_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the normal distribution is :  4315.386912655018\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the normal distribution is : \", norm_error(y_hat_normal3,y3_nor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example 4__\n",
    "\n",
    "Previously, we use the normal noise. Here, we also calculate the uniform noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Uniform distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87655425e+01,  1.00142891e+00, -8.49642705e-03])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x4, y4_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  359.02927875857927 , when θ =  [ 1.83428094e+01  1.00249981e+00 -4.70214356e-03] in 92465 iterations\n",
      "Execution time: 1115.0273158550262 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([5,5,5])\n",
    "Ex4_uni_result = linear_gradient_descent(linear_cost,x4,y4_uni,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x4,y4_uni,Ex4_uni_result[0]), \", when θ = \", Ex4_uni_result[0], \"in\", Ex4_uni_result[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_uniform4 = x4 @ Ex4_uni_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the uniform distribution is :  10916.589855546597\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the uniform distribution is : \", norm_error(y_hat_uniform4,y4_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Normal distribution__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.74141216,  0.99332467, -0.06167027])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x4, y4_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.31904309,  0.99439465, -0.05787925])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ex4_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_normal4 = x4 @ Ex4_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the normal distribution is :  8568.315466393502\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the normal distribution is : \", norm_error(y_hat_normal4,y4_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extra point__: compare uniform, standard normal distribution, and t distribution. We only use example 3 regression formula\n",
    "\n",
    "$$\n",
    "y = θ_0 + θ_1x_1 + θ_2x_1^2 + NormalNoise\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(90)\n",
    "x3_new, y3_uni_new, y3_nor_new, y3_t_new = CreateData3(400,-2,2,0,1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Uniform distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2593977 ,  1.04490667,  0.99941612])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3_new, y3_uni_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  0.615539695617249 , when θ =  [-0.13908796  0.99436568  1.00373415] in 1180 iterations\n",
      "Execution time: 9.505270004272461 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([4,4,4])\n",
    "Extra_uni = linear_gradient_descent(linear_cost,x3_new,y3_uni_new,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x3_new,y3_uni_new,Extra_uni[0]), \", when θ = \", Extra_uni[0], \"in\", Extra_uni[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_uniform_new = x3_new @ Extra_uni[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the uniform distribution is :  383.96573251788493\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the uniform distribution is : \", norm_error(y_hat_uniform_new,y3_uni_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normal distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05625889,  1.04754293,  0.99512461])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3_new, y3_nor_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  0.5401192121257384 , when θ =  [0.05719172 0.99988302 0.99919153] in 1203 iterations\n",
      "Execution time: 9.643182277679443 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([4,4,4])\n",
    "Extra_nor = linear_gradient_descent(linear_cost,x3_new,y3_nor_new,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x3_new,y3_nor_new,Extra_nor[0]), \", when θ = \", Extra_nor[0], \"in\", Extra_nor[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_normal_new = x3_new @ Extra_nor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the normal distribution is :  331.1953240358748\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the normal distribution is : \", norm_error(y_hat_normal_new,y3_nor_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__t distribution__*  with df = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33232176,  1.17634953,  0.98451532])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalized_inverse(x3_new, y3_t_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  1.000349718457809 , when θ =  [-0.2121408   1.12586265  0.98882873] in 1199 iterations\n",
      "Execution time: 9.69104790687561 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([4,4,4])\n",
    "Extra_t = linear_gradient_descent(linear_cost,x3_new,y3_t_new,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", linear_cost(x3_new,y3_t_new,Extra_t[0]), \", when θ = \", Extra_t[0], \"in\", Extra_t[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_t_new = x3_new @ Extra_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error norm for the t distribution is :  418.800846596549\n"
     ]
    }
   ],
   "source": [
    "print(\"The error norm for the t distribution is : \", norm_error(y_hat_t_new,y3_t_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution still has the minimum error norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2 Conclusion__\n",
    "\n",
    "If the error follows the normal distribution, then we have the minimum error norm, implying that the regression line contains a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we try a real dataset on kaggle: https://www.kaggle.com/nareshbhat/health-care-data-set-on-heart-attack-possibility\n",
    "heart = pd.read_csv(\"logistic_heart_disease.csv\")\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just choose several variables as predictors, and \"target\" as our response variable\n",
    "X = heart[['age','trestbps','chol','thalach','oldpeak']]\n",
    "Y = heart['target']\n",
    "x0 = np.ones(303)\n",
    "heart[\"x0\"] = x0\n",
    "x_data = np.array(heart[['x0','age','trestbps','chol','thalach','oldpeak']])\n",
    "y_data = np.array(heart['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06419043, -0.00046139, -0.00175788, -0.00054055,  0.00673133,\n",
       "       -0.13214493])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we use generalized inverse method to check the theta values\n",
    "generalized_inverse(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression, we apply the same gradient descent algorithm in linear regression, except a new loss function that need to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtite the sigmoid function, we can use this to calcualte yi later\n",
    "def Sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the cost function\n",
    "def logistic_cost(x,y,theta):\n",
    "    return np.sum(np.log(1+np.exp(x@theta)) - np.multiply(y, x@theta)) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingchen/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear cost function minimum:  0.5366693337161155 , when θ =  [-1.97192282  0.00210818 -0.01000777 -0.00308481  0.03403127 -0.97177001] in 20199 iterations\n",
      "Execution time: 685.7848329544067 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "theta0 = np.array([-2,-2,-2,-2,-2,-2])\n",
    "logistic_res = linear_gradient_descent(logistic_cost,x_data,y_data,theta0,1e-7)\n",
    "\n",
    "print(\"Linear cost function minimum: \", logistic_cost(x_data,y_data,logistic_res[0]), \", when θ = \", logistic_res[0], \"in\", logistic_res[1], \"iterations\")\n",
    "print(\"Execution time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6445111681482327"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_cost(x_data,y_data,generalized_inverse(x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366693337161155"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_cost(x_data,y_data,logistic_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value for the cost function of the gradeint descent algorithm is lower than the value in generalized inverse method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the yi values\n",
    "log_pred = Sigmoid(x_data@logistic_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pred_cat = np.array([1 if el > 0.5 else 0 for el in log_pred])\n",
    "log_pred_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Ci,j number of observations known to be in group i and predicted to be in group j\n",
    "table = confusion_matrix(y_data,log_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     No  Yes\n",
      "No   91   47\n",
      "Yes  31  134\n"
     ]
    }
   ],
   "source": [
    "confusion_df = pd.DataFrame(table, ['No','Yes'], ['No','Yes'])\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predictive model made 0.7425742574257426 % correct predictions on the heart dataset.\n"
     ]
    }
   ],
   "source": [
    "print('Our predictive model made',(91+134)/(91+134+31+47),'% correct predictions on the heart dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
